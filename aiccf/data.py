import os, sys, json
from collections import OrderedDict
import numpy as np
import pyqtgraph as pg
from pyqtgraph import metaarray
from pyqtgraph.Qt import QtGui, QtCore


class CCFAtlasData(object):
    
    #image_url = "http://download.alleninstitute.org/informatics-archive/current-release/mouse_ccf/average_template/average_template_{resolution}.nrrd"
    #label_url = "http://download.alleninstitute.org/informatics-archive/current-release/mouse_ccf/annotation/ccf_2016/annotation_{resolution}.nrrd"
    #ontology_url = "http://api.brain-map.org/api/v2/structure_graph_download/1.json"
    
    image_url = "file:///home/luke/work/allen_inst/ccf/ccfviewer/raw_data/average_template_{resolution}.nrrd"
    label_url = "file:///home/luke/work/allen_inst/ccf/ccfviewer/raw_data/annotation_{resolution}.nrrd"
    ontology_url = "file:///home/luke/work/allen_inst/ccf/ccfviewer/raw_data/ontology.json"
    
    def __init__(self, cache_path=None, resolution=None):
        self.image = None
        self.label = None
        self.ontology = None
        self.available_resolutions = [10, 25, 50, 100]
        
        # Decide on a default cache path
        if cache_path is None:
            if sys.platform == 'win32':
                cache_path = os.path.join(os.getenv("APPDATA"), 'aiccf')
            else:
                cache_path = os.path.join(os.path.expanduser("~"), ".local", "share", 'aiccf')
        self._cache_path = cache_path
        
        # Have we already cached some resolutions of the atlas?
        self.cached_resolutions = {}
        for res in self.available_resolutions:
            image_file = os.path.join(cache_path, '%dum'%res, 'image.ma')
            label_file = os.path.join(cache_path, '%dum'%res, 'label.ma')
            if os.path.isfile(image_file) and os.path.isfile(label_file):
                self.cached_resolutions[res] = (image_file, label_file)
        
        # Which resolution to load?
        if resolution is None:
            if len(self.cached_resolutions) == 0:
                # offer to download and cache 
                resolution = self.download_and_cache()
            else:
                # by default, pick the highest resolution that has already been cached
                resolution = min(self.cached_resolutions.keys())
        elif resolution not in self.cached_resolutions:
            resolution = self.download_and_cache(resolution)
            
        self._image_cache_file, self._label_cache_file = self.cached_resolutions[resolution]
        self.load_image_cache()
        self.load_label_cache()

    def download_and_cache(self, resolution=None):
        """Download atlas data, convert to intermediate format, and store in cache
        folder.
        """
        if resolution is None:
            from .ui import AtlasResolutionDialog, download
            dlg = AtlasResolutionDialog(self.available_resolutions, self.cached_resolutions.keys())
            dlg.exec_()
            resolution = dlg.selected_resolution()
            if resolution is None:
                raise Exception("No atlas resolution selected.")

        cache_path = self.cache_path(resolution)
        if not os.path.exists(cache_path):
            os.makedirs(cache_path)
        
        with pg.ProgressDialog("Preparing %dum CCF data" % resolution, maximum=6, nested=True) as dlg: 
            image_url = self.image_url.format(resolution=resolution)
            image_file = os.path.join(cache_path, image_url.split('/')[-1])
            image_cache = os.path.join(cache_path, "image.ma")
            download(image_url, image_file)
            dlg += 1
            
            label_url = self.label_url.format(resolution=resolution)
            label_file = os.path.join(cache_path, label_url.split('/')[-1])
            label_cache = os.path.join(cache_path, "label.ma")
            download(label_url, label_file)
            dlg += 1
            
            onto_file = os.path.join(cache_path, 'ontology.json')
            download(self.ontology_url, onto_file)
            
            self.load_image_data(image_file)
            dlg += 1
            writeFile(self.image, image_cache)
            dlg += 1
            
            self.load_label_data(label_file, onto_file)
            dlg += 1
            writeFile(self.label, label_cache)
            dlg += 1

        self.cached_resolutions[resolution] = (image_cache, label_cache)
        return resolution

    def cache_path(self, resolution):
        return os.path.join(self._cache_path, '%dum'%resolution)

    @property
    def shape(self):
        return self.image.shape

    def load_image_data(self, filename):
        self.image = read_nrrd_atlas(filename)
        
    def load_label_data(self, label_file, ontology_file):
        self.label = read_nrrd_labels(label_file, ontology_file)
        self.ontology = self.label._info[-1]['ontology']
        
    def load_image_cache(self):
        """Load a MetaArray-format atlas image file.
        """
        filename = self._image_cache_file
        self.image = metaarray.MetaArray(file=filename, readAllData=True)
        
    def load_label_cache(self):
        """Load a MetaArray-format atlas label file.
        """
        filename = self._label_cache_file
        self.label = metaarray.MetaArray(file=filename, readAllData=True)
        self.ontology = self.label._info[-1]['ontology']
        
    def ccf_transform(self):
        """Return a 3D transform that maps from atlas voxel coordinates to CCF
        coordinates (in unscaled meters).
        """
        
    def stereotaxic_transform(self):
        """Return a 3D transform that maps from atlas voxel coodrinates to 
        stereotaxic coordinates.
        """

    
def read_nrrd_atlas(nrrd_file):
    """
    Download atlas files from:
      http://help.brain-map.org/display/mouseconnectivity/API#API-DownloadAtlas
    """
    import nrrd

    data, header = nrrd.read(nrrd_file)

    # convert to ubyte to compress a bit
    np.multiply(data, 255./data.max(), out=data, casting='unsafe')
    data = data.astype('ubyte')

    # data must have axes (anterior, dorsal, right)
    # rearrange axes to fit -- CCF data comes in (posterior, inferior, right) order.
    data = data[::-1, ::-1, :]

    # voxel size in um
    vxsize = 1e-6 * float(header['space directions'][0][0])

    info = [
        {'name': 'anterior', 'values': np.arange(data.shape[0]) * vxsize, 'units': 'm'},
        {'name': 'dorsal', 'values': np.arange(data.shape[1]) * vxsize, 'units': 'm'},
        {'name': 'right', 'values': np.arange(data.shape[2]) * vxsize, 'units': 'm'},
        {'vxsize': vxsize}
    ]
    ma = metaarray.MetaArray(data, info=info)
    return ma


def read_nrrd_labels(nrrdFile, ontologyFile):
    """
    Download label files from:
      http://help.brain-map.org/display/mouseconnectivity/API#API-DownloadAtlas

    Download ontology files from:
      http://api.brain-map.org/api/v2/structure_graph_download/1.json

      see:
      http://help.brain-map.org/display/api/Downloading+an+Ontology%27s+Structure+Graph
      http://help.brain-map.org/display/api/Atlas+Drawings+and+Ontologies#AtlasDrawingsandOntologies-StructuresAndOntologies

    This method compresses the annotation data down to a 16-bit array by remapping
    the larger annotations to smaller, unused values.
    """
    global onto, ontology, data, mapping, inds, vxsize, info, ma

    import nrrd

    with pg.ProgressDialog("Loading annotation file...", 0, 5, wait=0, nested=True) as dlg:
        print "Loading annotation file..."
        pg.QtGui.QApplication.processEvents()
        # Read ontology and convert to flat table
        onto = json.load(open(ontologyFile, 'rb'))
        onto = parse_ontology(onto['msg'][0])
        l1 = max([len(row[2]) for row in onto])
        l2 = max([len(row[3]) for row in onto])
        ontology = np.array(onto, dtype=[('id', 'int32'), ('parent', 'int32'), ('name', 'S%d'%l1), ('acronym', 'S%d'%l2), ('color', 'S6')])    

        if dlg.wasCanceled():
            return
        dlg += 1

        # read annotation data
        data, header = nrrd.read(nrrdFile)

        if dlg.wasCanceled():
            return
        dlg += 1

        # data must have axes (anterior, dorsal, right)
        # rearrange axes to fit -- CCF data comes in (posterior, inferior, right) order.
        data = data[::-1, ::-1, :]

        if dlg.wasCanceled():
            return
        dlg += 1

    # compress down to uint16
    print "Compressing.."
    u = np.unique(data)
    
    # decide on a 32-to-64-bit label mapping
    mask = u <= 2**16-1
    next_id = 2**16-1
    mapping = OrderedDict()
    inds = set()
    for i in u[mask]:
        mapping[i] = i
        inds.add(i)
   
    with pg.ProgressDialog("Remapping annotations to 16-bit (please be patient with me; this can take several minutes) ...", 0, (~mask).sum(), wait=0, nested=True) as dlg:
        pg.QtGui.QApplication.processEvents()
        for i in u[~mask]:
            while next_id in inds:
                next_id -= 1
            mapping[i] = next_id
            inds.add(next_id)
            data[data == i] = next_id
            ontology['id'][ontology['id'] == i] = next_id
            ontology['parent'][ontology['parent'] == i] = next_id
            if dlg.wasCanceled():
                return
            dlg += 1
        
    data = data.astype('uint16')
    mapping = np.array(list(mapping.items()))    
 
    # voxel size in um
    vxsize = 1e-6 * float(header['space directions'][0][0])

    info = [
        {'name': 'anterior', 'values': np.arange(data.shape[0]) * vxsize, 'units': 'm'},
        {'name': 'dorsal', 'values': np.arange(data.shape[1]) * vxsize, 'units': 'm'},
        {'name': 'right', 'values': np.arange(data.shape[2]) * vxsize, 'units': 'm'},
        {'vxsize': vxsize, 'ai_ontology_map': mapping, 'ontology': ontology}
    ]
    ma = metaarray.MetaArray(data, info=info)
    return ma


def parse_ontology(root, parent=-1):
    ont = [(root['id'], parent, root['name'], root['acronym'], root['color_hex_triplet'])]
    for child in root['children']:
        ont += parse_ontology(child, root['id'])
    return ont


def writeFile(data, filename):
    dataDir = os.path.dirname(filename)
    if dataDir != '' and not os.path.exists(dataDir):
        os.makedirs(dataDir)

    tmp = filename + '.tmp'
    if max(data.shape) > 200 and min(data.shape) > 200:
        data.write(tmp, chunks=(200, 200, 200))
    else:
        data.write(tmp)
        
    os.rename(tmp, filename)
